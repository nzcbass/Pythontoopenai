{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiYGCP8jtQQux/ZgkcerxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzcbass/Pythontoopenai/blob/main/End_to_end_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports World cities and tidies it up\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Provide the path to your Excel file\n",
        "xlsx_path = \"worldcities.xlsx\"\n",
        "\n",
        "# Load the Excel file into a DataFrame\n",
        "df1 = pd.read_excel(xlsx_path)\n",
        "\n",
        "# Assuming your DataFrame is named df1\n",
        "df1 = df1.dropna(subset=['population'])\n",
        "\n",
        "# Remove rows where Population is less than 50,000\n",
        "df1 = df1[df1['population'] >= 50000]\n",
        "\n",
        "# Assuming your DataFrame is named df1\n",
        "df1 = df1.drop(['iso2', 'iso3', 'population'], axis=1)\n",
        "\n",
        "# Convert 'city' and 'country' columns to lowercase\n",
        "df1['city'] = df1['city'].str.lower()\n",
        "df1['country'] = df1['country'].str.lower()\n",
        "\n",
        "# Remove duplicate rows based on the 'city' column\n",
        "df1 = df1.drop_duplicates(subset='city', keep='first')\n",
        "\n",
        "# Remove duplicates based on both 'city' and 'country' columns in df1\n",
        "df1.drop_duplicates(subset=['city', 'country'], keep='first', inplace=True)\n",
        "\n",
        "# Assuming you have already loaded the DataFrame\n",
        "df1.loc[:, 'city'] = df1['city'].str.replace(r'\\s*city$', '', case=False, regex=True)\n",
        "\n",
        "# Copy df1 to create df2\n",
        "df2 = df1.copy()\n",
        "\n",
        "# Drop 'city' column from df2\n",
        "df2 = df2.drop(['city'], axis=1)\n",
        "\n",
        "# Remove duplicate rows based on the 'country' column from df2\n",
        "df2 = df2.drop_duplicates(subset='country', keep='first')\n",
        "\n",
        "# Display the DataFrames or perform any other operations as needed\n",
        "print(\"df1:\")\n",
        "print(df1.head())\n",
        "\n",
        "print(\"\\ndf2:\")\n",
        "print(df2.head())\n",
        "\n",
        "# Adding a new row with \"US\" in the \"country\" column\n",
        "new_rows = pd.DataFrame({'country': ['us', 'usa', 'united states of america', 'uk']})\n",
        "df2 = pd.concat([df2, new_rows], ignore_index=True)\n",
        "\n",
        "# Remove duplicates in df1 based on 'city' and 'country'\n",
        "df1 = df1.drop_duplicates(subset=['city', 'country'], keep='first')\n",
        "\n",
        "# Check for duplicates in 'df1'\n",
        "duplicates_df1 = df1[df1.duplicated(subset=['city', 'country'], keep=False)]\n",
        "\n",
        "# Check for duplicates in 'df2'\n",
        "duplicates_df2 = df2[df2.duplicated(subset=['country'], keep=False)]\n",
        "\n",
        "# Remove blank rows in df1\n",
        "df1 = df1.dropna()\n",
        "\n",
        "# Remove blank rows in df2\n",
        "df2 = df2.dropna()\n",
        "\n",
        "# Display the duplicates in 'df1'\n",
        "print(\"Duplicates in df1:\")\n",
        "print(duplicates_df1)\n",
        "\n",
        "# Display the duplicates in 'df2'\n",
        "print(\"\\nDuplicates in df2:\")\n",
        "print(duplicates_df2)\n",
        "\n",
        "# Count rows in df1\n",
        "rows_df1 = len(df1)\n",
        "print(f\"Number of rows in df1: {rows_df1}\")\n",
        "\n",
        "# Count rows in df2\n",
        "rows_df2 = len(df2)\n",
        "print(f\"Number of rows in df2: {rows_df2}\")\n",
        "\n",
        "\n",
        "# Save df1 to a CSV file\n",
        "df1.to_csv('world_cities_countries.csv', index=False)\n",
        "\n",
        "# Save df2 to a CSV file\n",
        "df2.to_csv('world_countries.csv', index=False)\n",
        "\n",
        "\n",
        "# Check if \"US\" is in the \"country\" column\n",
        "is_us_in_df2 = 'us' in df2['country'].values\n",
        "\n",
        "# print(is_us_in_df2)\n"
      ],
      "metadata": {
        "id": "qUde1pEFrAsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Takes the json filed and creates location data etc from it\n",
        "\n",
        "# this code is perfect, do no change\n",
        "#  it loads the json, adds jon numbers\n",
        "#  saves back down for later use\n",
        "#  !!!!!DO NOT CHANGE!!!!!\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Assuming 'resume.json' is in a directory called 'resumes' in the same parent directory as your Python script\n",
        "json_file_path1 = \"/content/CV_parsed_by_CV_Parser_Premium-23.json\"  # Relative path\n",
        "\n",
        "# Open the JSON file and load its contents into a Python dictionary\n",
        "with open(json_file_path1, 'r') as file:\n",
        "    resume_data = json.load(file)\n",
        "\n",
        "# Labeling the job entries\n",
        "job_count = 1\n",
        "for experience in resume_data['profile']['professional_experiences']:\n",
        "    experience['job_label'] = f'Job_{job_count}'\n",
        "    job_count += 1\n",
        "\n",
        "# Save the modified data back to the JSON file\n",
        "output_json_path = \"/content/jobslabeled.json\"\n",
        "with open(output_json_path, 'w') as output_file:\n",
        "    json.dump(resume_data, output_file, indent=2)\n",
        "\n",
        "print(f\"Job labeling completed. Labeled data saved to {output_json_path}\")\n",
        "\n",
        "# Now 'resume_data' contains the contents of the JSON file\n",
        "# print(json.dumps(resume_data, indent=2))\n",
        "\n",
        "# Load df1 from the Excel file\n",
        "df1_path = \"/content/world_cities_countries.csv\"\n",
        "df1 = pd.read_csv(df1_path)\n",
        "\n",
        "\n",
        "def split_and_create_columns(location):\n",
        "    if pd.notna(location):\n",
        "        substrings = re.split(r'[^\\w]+', location)\n",
        "        substrings = [entry.strip() for entry in substrings]\n",
        "        substrings = [remove_special_terms(entry) for entry in substrings]\n",
        "\n",
        "        if any(\"justice\" in entry.lower() or \"precinct\" in entry.lower() for entry in substrings):\n",
        "            substrings.append(\"new zealand\")\n",
        "\n",
        "        if any(\"christchurch\" in entry.lower() or \"convention\" in entry.lower() for entry in substrings):\n",
        "            substrings.append(\"new zealand\")\n",
        "\n",
        "        return substrings\n",
        "\n",
        "    return pd.NA\n",
        "\n",
        "def remove_special_terms(substring):\n",
        "    special_terms = [\"plaza\", \"street\", \"st\", \"road\", \"rd\", \"avenue\", \"close\", \"motorway\", \"highway\",\n",
        "                     \"po\", \"PO\", \"new zealand|po\", \"office\", \"drive\", \"cor.\", \"ave.\", \"ave\", \"level\", \"lvl\",\n",
        "                     \"box\", \"lv\", \"village\", \"vellage\", \"building\", \"bldg\", \"city\", \"albany\"]\n",
        "\n",
        "    pattern = r'\\b(?:' + '|'.join(re.escape(term) for term in special_terms) + r')\\b'\n",
        "\n",
        "    substring = re.sub(pattern, '', substring, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    if \"rubber\" in substring.lower():\n",
        "        substring = substring.replace(\"rubber\", \"\").strip()\n",
        "\n",
        "    if \"tire\" in substring.lower():\n",
        "        substring = substring.replace(\"tire\", \"\").strip()\n",
        "\n",
        "    return substring\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    json_file_path2 = \"jobslabeled.json\"\n",
        "    df = pd.json_normalize(json.load(open(json_file_path2, 'r'))['profile']['professional_experiences'])\n",
        "\n",
        "    # Focus on the 'location' column\n",
        "    df['location'] = df['location'].str.lower()\n",
        "    new_columns = df['location'].apply(split_and_create_columns).apply(pd.Series)\n",
        "\n",
        "    # Label the new columns with subscripts and append numbers\n",
        "    new_columns.columns = [f'subscript_{i+1}' for i in range(new_columns.shape[1])]\n",
        "\n",
        "    # Concatenate the new columns to the original DataFrame\n",
        "    df = pd.concat([df, new_columns], axis=1)\n",
        "\n",
        "# Save df to a CSV file\n",
        "df.to_csv('output_data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo9LKjwrrci1",
        "outputId": "f203fda3-fd67-4715-924f-c743c6ea0ca6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job labeling completed. Labeled data saved to /content/jobslabeled.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CndfYExK5Wom",
        "outputId": "122fbd47-1072-4a61-fb9b-49dd85bd73c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 1:\n",
            "  Countries Matched: \n",
            "  Cities Matched: \n",
            "\n",
            "Row 2:\n",
            "  Countries Matched: \n",
            "  Cities Matched: batangas\n",
            "\n",
            "Row 3:\n",
            "  Countries Matched: \n",
            "  Cities Matched: batangas\n",
            "\n",
            "Row 4:\n",
            "  Countries Matched: saudi arabia\n",
            "  Cities Matched: \n",
            "\n",
            "Row 5:\n",
            "  Countries Matched: saudi arabia\n",
            "  Cities Matched: \n",
            "\n",
            "Row 6:\n",
            "  Countries Matched: \n",
            "  Cities Matched: \n",
            "\n",
            "Row 7:\n",
            "  Countries Matched: \n",
            "  Cities Matched: \n",
            "\n",
            "Row 8:\n",
            "  Countries Matched: \n",
            "  Cities Matched: \n",
            "\n",
            "Row 9:\n",
            "  Countries Matched: singapore\n",
            "  Cities Matched: singapore\n",
            "\n",
            "Row 10:\n",
            "  Countries Matched: \n",
            "  Cities Matched: \n",
            "\n",
            "Row 11:\n",
            "  Countries Matched: \n",
            "  Cities Matched: \n",
            "\n",
            "     city country\n",
            "2307  ica    peru\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load df & df1 & df2\n",
        "df_path = \"/content/output_data.csv\"\n",
        "df = pd.read_csv(df_path)\n",
        "\n",
        "df1_path = \"/content/world_countries.csv\"\n",
        "df1 = pd.read_csv(df1_path)\n",
        "\n",
        "df2_path = \"/content/world_cities_countries.csv\"\n",
        "df2 = pd.read_csv(df2_path)\n",
        "\n",
        "# Convert columns to string type\n",
        "df['location'] = df['location'].astype(str)\n",
        "df1['country'] = df1['country'].astype(str)\n",
        "df2['city'] = df2['city'].astype(str)\n",
        "\n",
        "# Create a new column to store the found country names\n",
        "# df['found_countries'] = None\n",
        "\n",
        "# Create a new column 'countries_matched' in df\n",
        "df['countries_matched'] = df['location'].apply(lambda x: ', '.join(country for country in df1['country'] if f\" {country.lower()} \" in f\" {x.lower()} \"))\n",
        "\n",
        "# Create a new column 'cities_matched' in df\n",
        "df['cities_matched'] = df['location'].apply(lambda x: ', '.join(city for city in df2['city'] if f\" {city.lower()} \" in f\" {x.lower()} \"))\n",
        "\n",
        "\n",
        "\n",
        "# Ammendments to search criteria\n",
        "\n",
        "# Check if 'justice' and 'precinct' are found in the 'location' column\n",
        "condition = df['location'].str.contains('justice', case=False) & df['location'].str.contains('precinct', case=False)\n",
        "# If the condition is met, set 'New Zealand' in the 'countries_matched' column\n",
        "df.loc[condition, 'countries_matched'] = 'new zealand'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a new column 'Final_match' with capitalized words and no leading spaces\n",
        "df['Final_match'] = df.apply(lambda row: ' '.join([(word.upper() if len(word) == 2 else (word.capitalize() if len(word) <= 3 else word.title())) for word in row[['countries_matched', 'cities_matched']]]).lstrip(), axis=1)\n",
        "\n",
        "# Save df as a CSV file\n",
        "csv_output_path = \"city_country_output_data.csv\"\n",
        "df.to_csv(csv_output_path, index=False)\n",
        "# print(f\"DataFrame saved to {csv_output_path}\")\n",
        "\n",
        "# Explicitly print matched values\n",
        "for index, row in df.iterrows():\n",
        "    print(f\"Row {index + 1}:\")\n",
        "    print(f\"  Countries Matched: {row['countries_matched']}\")\n",
        "    print(f\"  Cities Matched: {row['cities_matched']}\")\n",
        "    print()\n",
        "\n",
        "# Filter rows where 'city' is equal to 'ica'\n",
        "filtered_rows = df2[df2['city'].apply(lambda x: f\" ica \" in f\" {x.lower()} \")]\n",
        "\n",
        "# Print the result\n",
        "print(filtered_rows)\n"
      ]
    }
  ]
}