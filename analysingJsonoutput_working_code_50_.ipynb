{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr+lvmeaC9rG/qWaVw2rKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzcbass/Pythontoopenai/blob/main/analysingJsonoutput_working_code_50_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyXBNmCv2siT",
        "outputId": "c263b49c-eebd-4e31-c7c6-19e22f9e49aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job labeling completed. Labeled data saved to /content/jobslabeled.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Assuming 'resume.json' is in a directory called 'resumes' in the same parent directory as your Python script\n",
        "json_file_path1 = \"/content/CV_parsed_by_CV_Parser_Premium-15.json\"  # Relative path\n",
        "\n",
        "# Open the JSON file and load its contents into a Python dictionary\n",
        "with open(json_file_path1, 'r') as file:\n",
        "    resume_data = json.load(file)\n",
        "\n",
        "# Labeling the job entries\n",
        "job_count = 1\n",
        "for experience in resume_data['profile']['professional_experiences']:\n",
        "    experience['job_label'] = f'Job_{job_count}'\n",
        "    job_count += 1\n",
        "\n",
        "# Save the modified data back to the JSON file\n",
        "output_json_path = \"/content/jobslabeled.json\"\n",
        "with open(output_json_path, 'w') as output_file:\n",
        "    json.dump(resume_data, output_file, indent=2)\n",
        "\n",
        "print(f\"Job labeling completed. Labeled data saved to {output_json_path}\")\n",
        "\n",
        "# Now 'resume_data' contains the contents of the JSON file\n",
        "# print(json.dumps(resume_data, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def json_to_dataframe(json_file_path):\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        resume_data = json.load(file)\n",
        "\n",
        "    df = pd.json_normalize(resume_data['profile']['professional_experiences'])\n",
        "\n",
        "    if 'description' in df.columns:\n",
        "        df = df.drop('description', axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def split_and_create_columns(location):\n",
        "    if pd.notna(location):\n",
        "        # Use a more comprehensive regex to handle special characters\n",
        "        substrings = re.split(r'[^\\w]+', location)\n",
        "        substrings = [entry.strip() for entry in substrings]\n",
        "\n",
        "        # Remove specific terms like \"plaza,\" \"street,\" etc.\n",
        "        substrings = [remove_special_terms(entry) for entry in substrings]\n",
        "\n",
        "        # Check if \"Africa\" is present and the preceding word is \"South\"\n",
        "        for i, entry in enumerate(substrings):\n",
        "            if entry.lower() == \"africa\" and i > 0 and substrings[i-1].lower() == \"south\":\n",
        "                substrings[i] = \"\"  # Remove \"Africa\" from the current cell\n",
        "                substrings[i-1] = \"South Africa\"\n",
        "\n",
        "            # Check if \"Arabia\" is present and the preceding word is \"Saudi\"\n",
        "            if entry.lower() == \"arabia\" and i > 0 and substrings[i-1].lower() == \"saudi\":\n",
        "                substrings[i] = \"\"  # Remove \"Arabia\" from the current cell\n",
        "                substrings[i-1] = \"Saudi Arabia\"\n",
        "\n",
        "            # Check if \"Emirates\" is present and the two preceding words are \"United Arab\"\n",
        "            if entry.lower() == \"emirates\" and i > 1 and substrings[i-1].lower() == \"arab\" and substrings[i-2].lower() == \"united\":\n",
        "                substrings[i] = \"\"  # Remove \"Emirates\" from the current cell\n",
        "                substrings[i-1] = \"\"  # Remove \"Arab\" from the preceding cell\n",
        "                substrings[i-2] = \"United Arab Emirates\"\n",
        "\n",
        "        column_headers = [f'substring_{i+1}' for i in range(len(substrings))]\n",
        "        substrings_dict = dict(zip(column_headers, substrings))\n",
        "        return substrings_dict\n",
        "\n",
        "    return pd.NA\n",
        "\n",
        "\n",
        "def remove_special_terms(substring):\n",
        "    # Add logic to remove specific terms like \"plaza,\" \"street,\" etc.\n",
        "    special_terms = [\"plaza\", \"street\", \"st\", \"road\", \"rd\", \"avenue\", \"close\", \"motorway\", \"highway\",\n",
        "                     \"po\", \"PO\", \"new zealand|po\", \"office\", \"drive\", \"cor.\", \"ave.\", \"ave\", \"level\", \"lvl\",\n",
        "                     \"box\", \"lv\", \"village\", \"vellage\", \"building\", \"bldg\", \"city\",\"albany\"]\n",
        "\n",
        "    # Construct a regex pattern to match whole words\n",
        "    pattern = r'\\b(?:' + '|'.join(re.escape(term) for term in special_terms) + r')\\b'\n",
        "\n",
        "    # Use regex to replace matched terms with an empty string\n",
        "    substring = re.sub(pattern, '', substring, flags=re.IGNORECASE).strip()\n",
        "\n",
        "    return substring\n",
        "\n",
        "def find_city(substring):\n",
        "    if pd.notna(substring):\n",
        "        # Check if the substring is a list\n",
        "        if isinstance(substring, list):\n",
        "            matching_cities = df1[df1['City'].isin(substring)]['City'].tolist()\n",
        "            return matching_cities\n",
        "        else:\n",
        "            # Check if the substring matches any city in df1\n",
        "            matching_city = df1[df1['City'].str.match(f\"^{substring}$\", case=False, na=False)]\n",
        "\n",
        "            if not matching_city.empty:\n",
        "                return matching_city['City'].values[0]\n",
        "\n",
        "    return pd.NA\n",
        "\n",
        "def get_country_matched(row):\n",
        "    cities = []\n",
        "\n",
        "    for col in df.filter(like='substring_'):\n",
        "        if isinstance(row[col], list):\n",
        "            cities.extend(city for city in row[col] if isinstance(city, str) and pd.notna(city))\n",
        "        elif isinstance(row[col], str) and pd.notna(row[col]):\n",
        "            cities.append(row[col])\n",
        "\n",
        "    if cities:\n",
        "        unique_cities = set(cities)\n",
        "        if len(unique_cities) == 1:\n",
        "            return df1[df1['City'] == unique_cities.pop()]['Country'].values[0]\n",
        "        elif len(unique_cities) > 1:\n",
        "            return ', '.join(df1[df1['City'].isin(unique_cities)]['Country'].tolist())\n",
        "\n",
        "    # Handle cases where cities is empty\n",
        "    return 'Review CV' if not any(isinstance(row[col], (float, pd.NA)) for col in df.filter(like='substring_')) else pd.NA\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    json_file_path2 = \"jobslabeled.json\"\n",
        "    df = json_to_dataframe(json_file_path2)\n",
        "    df['location'] = df['location'].str.lower()\n",
        "    df = df.join(df['location'].apply(split_and_create_columns).apply(pd.Series))\n",
        "\n",
        "    df1 = pd.read_excel(\"/content/Updated_World_Cities.xlsx\")\n",
        "\n",
        "    # Extract city columns and handle NA values\n",
        "    for col in df.filter(like='substring_').columns:\n",
        "        col_city = f'{col}_city'\n",
        "        df[col_city] = df[col].apply(find_city)\n",
        "        df[col_city] = df[col_city].astype(str)\n",
        "        df[col_city].replace('nan', pd.NA, inplace=True)  # Replace 'nan' strings with actual NA values\n",
        "\n",
        "    # Continue with the rest of the code\n",
        "    df['Country Matched'] = df.apply(lambda row: get_country_matched(row.filter(like='substring_')), axis=1)\n",
        "\n",
        "    # Update the logic for Final_country_matched\n",
        "    df['Final_country_matched'] = df['Country Matched'].apply(lambda x: x.split(', ')[-1] if pd.notna(x) and ', ' in x else x)\n",
        "\n",
        "    # Other cleaning steps\n",
        "    df['location'] = df['location'].str.replace(r'\\b(city)\\b|\\d', '', case=False, regex=True)\n",
        "    df['location'] = df['location'].str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
        "    df['location'] = df['location'].str.strip()\n",
        "    df['location'].replace('', pd.NA, inplace=True)\n",
        "\n",
        "    # Add this line at the end of your script\n",
        "    df['Final_country_matched'].fillna('Review Resume', inplace=True)\n",
        "\n",
        "    csv_output_path = \"output_data.csv\"\n",
        "    df.to_csv(csv_output_path, index=False)\n",
        "    print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7Ddwn5gAlsZ",
        "outputId": "a3c141f1-b234-40fd-c0c4-1779b3027830"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   is_current  duration_in_months                                company  \\\n",
            "0       False                  30  All trades laboure hire ltd/Ele group   \n",
            "1       False                  52      Hilmarcs Construction Corporation   \n",
            "2       False                  12      Hilmarcs Construction Corporation   \n",
            "3       False                   2      Hilmarcs Construction Corporation   \n",
            "4       False                  14                            MDC / DDTKI   \n",
            "\n",
            "                                        location               title  \\\n",
            "0                               ryman healthcare   Carpenter/builder   \n",
            "1  okada manila admintiger paraaque  philippines   foreman carpenter   \n",
            "2                 pilippine arena bocaue bulacan  Lead Man Carpenter   \n",
            "3                  alphaland makati  philippines  Lead Man Carpenter   \n",
            "4            glorietta  and  makati  philippines           Carpenter   \n",
            "\n",
            "  job_label  start_date.year  start_date.month  end_date.year  end_date.month  \\\n",
            "0     Job_1             2017                 7           2019              12   \n",
            "1     Job_2             2013                 3           2017               6   \n",
            "2     Job_3             2012                 3           2013               2   \n",
            "3     Job_4             2012                 1           2012               2   \n",
            "4     Job_5             2010                11           2011              12   \n",
            "\n",
            "   ...  substring_7 substring_1_city substring_2_city substring_3_city  \\\n",
            "0  ...          NaN             <NA>             <NA>             <NA>   \n",
            "1  ...  philippines             <NA>           Manila             <NA>   \n",
            "2  ...          NaN             <NA>             <NA>           Bocaue   \n",
            "3  ...          NaN             <NA>           Makati             <NA>   \n",
            "4  ...  philippines             <NA>             <NA>             <NA>   \n",
            "\n",
            "  substring_4_city substring_5_city substring_6_city substring_7_city  \\\n",
            "0             <NA>             <NA>             <NA>             <NA>   \n",
            "1             <NA>             <NA>             <NA>      Philippines   \n",
            "2          Bulacan             <NA>             <NA>             <NA>   \n",
            "3      Philippines             <NA>             <NA>             <NA>   \n",
            "4             <NA>           Makati             <NA>      Philippines   \n",
            "\n",
            "            Country Matched Final_country_matched  \n",
            "0                                                  \n",
            "1  Philippines, Philippines           Philippines  \n",
            "2  Philippines, Philippines           Philippines  \n",
            "3  Philippines, Philippines           Philippines  \n",
            "4  Philippines, Philippines           Philippines  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    }
  ]
}