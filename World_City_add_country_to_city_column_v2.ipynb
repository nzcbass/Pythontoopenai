{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL36hrK+aKONbp9x60OC9B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzcbass/Pythontoopenai/blob/main/World_City_add_country_to_city_column_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "NZuhrHe4ax3R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the original DataFrame from the Excel file\n",
        "xlsx_file_path = \"/content/World Cities.xlsx\"\n",
        "df1 = pd.read_excel(xlsx_file_path)\n",
        "\n",
        "# Function to remove suffix from 'City' column\n",
        "def remove_city_suffix(city):\n",
        "    if city.lower().endswith('city'):\n",
        "        city = city[:-5]\n",
        "    return city\n",
        "\n",
        "# Apply the remove_city_suffix function to the 'City' column\n",
        "df1['City'] = df1['City'].apply(remove_city_suffix)\n",
        "\n",
        "# Convert the 'City' column to lowercase for case-insensitive comparison\n",
        "df1['City'] = df1['City'].str.lower()\n",
        "\n",
        "# Identify duplicates in 'City' column\n",
        "duplicate_cities = df1.duplicated(subset=['City'], keep=False)\n",
        "\n",
        "# Check if duplicates have the same values in 'Country' column\n",
        "duplicate_city_country = df1[duplicate_cities].duplicated(subset=['City', 'Country'], keep='first')\n",
        "\n",
        "# Filter the DataFrame to keep only non-duplicate rows\n",
        "df1_cleaned = df1[~(duplicate_cities & ~duplicate_city_country)]\n",
        "\n",
        "# Print unique values in 'City' column after cleaning\n",
        "# print(\"Unique values in 'City' column after cleaning:\")\n",
        "# print(df1_cleaned['City'].unique())\n",
        "\n",
        "# Sort the DataFrame by 'City' column\n",
        "df1_sorted = df1_cleaned.sort_values(by='City')\n",
        "\n",
        "# Identify duplicates in the 'City' and 'Country' columns\n",
        "duplicate_city_country = df1_sorted.duplicated(subset=['City', 'Country'], keep=False)\n",
        "\n",
        "# Remove duplicates from the original DataFrame\n",
        "df1_cleaned_final = df1_sorted[~duplicate_city_country].drop_duplicates(subset=['City', 'Country'], keep='first')\n",
        "\n",
        "# Display the top 50 results with 'City' and 'Country' columns from the cleaned DataFrame\n",
        "# print(\"Top 50 Results from Cleaned DataFrame:\")\n",
        "# print(df1_cleaned_final[['City', 'Country']].head(50))\n",
        "\n",
        "# Save the resulting cleaned DataFrame to an Excel file\n",
        "df1_cleaned_final.to_excel(\"/content/Updated_World_Cities.xlsx\", index=False)\n"
      ]
    }
  ]
}