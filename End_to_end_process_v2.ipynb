{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoM+PAU9UzmVApYo8LsIUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzcbass/Pythontoopenai/blob/main/End_to_end_process_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Provide the path to your Excel file (Desktop)\n",
        "xlsx_path = \"UL worldcities.xlsx\"\n",
        "\n",
        "# Load the Excel file into a DataFrame\n",
        "df1 = pd.read_excel(xlsx_path)\n",
        "\n",
        "# Assuming your DataFrame is named df1\n",
        "df1 = df1.dropna(subset=['population'])\n",
        "\n",
        "# Remove rows where Population is less than 50,000\n",
        "df1 = df1[df1['population'] >= 50000]\n",
        "\n",
        "# Assuming your DataFrame is named df1\n",
        "df1 = df1.drop(['iso2', 'iso3', 'population'], axis=1)\n",
        "\n",
        "# Convert 'city' and 'country' columns to lowercase\n",
        "df1['city'] = df1['city'].str.lower().str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
        "df1['country'] = df1['country'].str.lower().str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
        "\n",
        "# Remove duplicate rows based on the 'city' column\n",
        "df1 = df1.drop_duplicates(subset='city', keep='first')\n",
        "\n",
        "# Remove duplicates based on both 'city' and 'country' columns in df1\n",
        "df1.drop_duplicates(subset=['city', 'country'], keep='first', inplace=True)\n",
        "\n",
        "# Delete the row where 'city' is 'm.ə. rəsulzadə' from df1\n",
        "df1 = df1[df1['city'] != 'm.ə. rəsulzadə'].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
        "\n",
        "# Assuming you have already loaded the DataFrame\n",
        "df1.loc[:, 'city'] = df1['city'].str.replace(r'\\s*city$', '', case=False, regex=True)\n",
        "\n",
        "# Copy df1 to create df2\n",
        "df2 = df1.copy()\n",
        "\n",
        "# Drop 'city' column from df2\n",
        "df2 = df2.drop(['city'], axis=1)\n",
        "\n",
        "# Remove duplicate rows based on the 'country' column from df2\n",
        "df2 = df2.drop_duplicates(subset='country', keep='first')\n",
        "\n",
        "# Adding a new row with \"Mississippi\" in the \"city\" column and \"United States\" in the \"country\" column\n",
        "new_row = pd.DataFrame({'city': ['mississippi'], 'country': ['united states']})\n",
        "df1 = pd.concat([df1, new_row], ignore_index=True)\n",
        "\n",
        "# Adding a new row with \"K.S.A.\" in the \"city\" column and \"Saudi Arabia\" in the \"country\" column\n",
        "new_row = pd.DataFrame({'city': ['k.s.a.'], 'country': ['Saudi Arabia']})\n",
        "df1 = pd.concat([df1, new_row], ignore_index=True)\n",
        "\n",
        "# Adding a new row with \"K.S.A.\" in the \"city\" column and \"Saudi Arabia\" in the \"country\" column\n",
        "new_row = pd.DataFrame({'city': ['k.s.a'], 'country': ['Saudi Arabia']})\n",
        "df1 = pd.concat([df1, new_row], ignore_index=True)\n",
        "\n",
        "# Adding a new row with \"US\" in the \"country\" column\n",
        "new_rows = pd.DataFrame({'country': ['us', 'usa', 'united states of america', 'uk']})\n",
        "df2 = pd.concat([df2, new_rows], ignore_index=True)\n",
        "\n",
        "# Replace \"Congo (Kinshasa)\" with \"Congo\" in the 'country' column of df2\n",
        "df2['country'] = df2['country'].replace({\"congo (kinshasa)\": \"congo\"})\n",
        "\n",
        "# Replace \"Congo (Kinshasa)\" with \"Congo\" in the 'country' column of df1\n",
        "df1['country'] = df1['country'].replace({\"congo (kinshasa)\": \"congo\"})\n",
        "df1['country'] = df1['country'].replace({\"congo (brazzaville)\": \"congo\"})\n",
        "\n",
        "# Remove duplicates in df1 based on 'city' and 'country'\n",
        "df1 = df1.drop_duplicates(subset=['city', 'country'], keep='first')\n",
        "\n",
        "# Save df1 to a CSV file\n",
        "df1.to_csv('DL world_cities_countries.csv', index=False)\n",
        "\n",
        "# Save df2 to a CSV file\n",
        "df2.to_csv('DL world_countries.csv', index=False)\n",
        "\n",
        "# Display the DataFrames or perform any other operations as needed\n",
        "print(\"df1:\")\n",
        "print(df1.head())\n",
        "\n",
        "print(\"\\ndf2:\")\n",
        "print(df2.head())\n",
        "\n",
        "# Set display options to show all rows and columns\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "# Look up countries with the city 'k.s.a'\n",
        "countries_with_ksa = df1[df1['city'].str.contains('k.s.a.')]['country'].unique()\n",
        "\n",
        "# Print the result\n",
        "print(\"Countries with the city 'K.S.A.':\", countries_with_ksa)\n",
        "\n",
        "# Show duplicates in the 'city' column\n",
        "duplicate_cities = df1[df1['city'].duplicated(keep=False)]\n",
        "\n",
        "# # Print the result\n",
        "# print(\"Duplicate cities in df1:\")\n",
        "# print(duplicate_cities)\n",
        "\n",
        "# Find rows where 'city' is equal to 'k.s.a.' or 'k.s.a'\n",
        "filtered_rows = df1[df1['city'].isin(['k.s.a.', 'k.s.a'])]\n",
        "\n",
        "# Print the result\n",
        "print(\"Rows where 'city' is equal to 'k.s.a.' or 'k.s.a':\")\n",
        "print(filtered_rows[['city', 'country']])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Displaying all cities and countries where city is \"k.s.a.\"\n",
        "# print(\"Cities and countries where city is 'k.s.a.':\")\n",
        "# print(df1[df1['city'] == 'k.s.a.'])\n",
        "\n",
        "# # Displaying all cities and countries where country is \"Indonesia\"\n",
        "# print(\"\\nCities and countries in Indonesia:\")\n",
        "# print(df1[df1['country'] == 'indonesia'])\n",
        "\n",
        "\n",
        "# # Reset display options to the default values if needed\n",
        "# pd.set_option('display.max_rows', 10)  # Set the desired number or remove this line to reset to default\n",
        "# pd.set_option('display.max_columns', 20)  # Set the desired number or remove this line to reset to default\n",
        "# pd.set_option('display.width', 80)  # Set the desired width or remove this line to reset to default\n",
        "\n",
        "\n",
        "# # Check if \"batangas\" is in the \"country\" column of df1\n",
        "# is_batangas_in_df1 = 'Al Khobar' in df1['city'].values\n",
        "\n",
        "# # Check if \"batangas\" is in the \"country\" column of df2\n",
        "# is_batangas_in_df2 = 'Al Khobar' in df2['country'].values\n",
        "\n",
        "# print(f\"Is 'k.s.a' in df1 country column? {is_batangas_in_df1}\")\n",
        "# print(f\"Is 'k.s.a.' in df2 country column? {is_batangas_in_df2}\")\n",
        "\n",
        "\n",
        "# Troubleshooting prints below\n",
        "\n",
        "# # Set pandas display options to show all rows and columns\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.max_columns', None)\n",
        "\n",
        "# # Define the pattern for characters that are not letters, digits, spaces, or @ symbol\n",
        "# pattern = re.compile(r'[^a-zA-Z0-9\\s@]')\n",
        "\n",
        "# # Filter rows in df1 where 'city' or 'country' columns contain numbers or symbols\n",
        "# rows_with_numbers_symbols_df1 = df1[df1['city'].str.contains(pattern) | df1['country'].str.contains(pattern)]\n",
        "\n",
        "# # Filter rows in df2 where 'country' column contains numbers or symbols\n",
        "# rows_with_numbers_symbols_df2 = df2[df2['country'].str.contains(pattern)]\n",
        "\n",
        "# # Display the filtered rows\n",
        "# # print(\"Rows in df1 with numbers or symbols:\")\n",
        "# # print(rows_with_numbers_symbols_df1)\n",
        "\n",
        "# # print(\"\\nRows in df2 with numbers or symbols:\")\n",
        "# # print(rows_with_numbers_symbols_df2)\n",
        "\n",
        "# # Reset pandas display options to default\n",
        "# pd.reset_option('display.max_rows')\n",
        "# pd.reset_option('display.max_columns')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qUde1pEFrAsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c171c8c-e6f4-4ee6-ccef-43ca62517c68"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df1:\n",
            "        city    country\n",
            "0      tokyo      japan\n",
            "1    jakarta  indonesia\n",
            "2      delhi      india\n",
            "3  guangzhou      china\n",
            "4     mumbai      india\n",
            "\n",
            "df2:\n",
            "       country\n",
            "0        japan\n",
            "1    indonesia\n",
            "2        india\n",
            "3        china\n",
            "4  philippines\n",
            "Countries with the city 'K.S.A.': ['indonesia' 'sudan' 'somalia' 'kazakhstan' 'turkey' 'poland' 'india'\n",
            " 'russia' 'china' 'Saudi Arabia']\n",
            "Rows where 'city' is equal to 'k.s.a.' or 'k.s.a':\n",
            "         city       country\n",
            "10315  k.s.a.  Saudi Arabia\n",
            "10316   k.s.a  Saudi Arabia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #  Takes the json filed and creates location data etc from it\n",
        "\n",
        "# # this code is perfect, do no change\n",
        "# #  it loads the json, adds jon numbers\n",
        "# #  saves back down for later use\n",
        "# #  !!!!!DO NOT CHANGE!!!!!\n",
        "\n",
        "# import json\n",
        "# import pandas as pd\n",
        "# import re\n",
        "\n",
        "# # Assuming 'resume.json' is in a directory called 'resumes' in the same parent directory as your Python script\n",
        "# json_file_path1 = \"/content/UL CV_parsed_by_CV_Parser_Premium-23.json\"  # On desk top\n",
        "\n",
        "# # Open the JSON file and load its contents into a Python dictionary\n",
        "# with open(json_file_path1, 'r') as file:\n",
        "#     resume_data = json.load(file)\n",
        "\n",
        "# # Labeling the job entries\n",
        "# job_count = 1\n",
        "# for experience in resume_data['profile']['professional_experiences']:\n",
        "#     experience['job_label'] = f'Job_{job_count}'\n",
        "#     job_count += 1\n",
        "\n",
        "# # Save the modified data back to the JSON file\n",
        "# output_json_path = \"/content/DL jobslabeled.json\"\n",
        "# with open(output_json_path, 'w') as output_file:\n",
        "#     json.dump(resume_data, output_file, indent=2)\n",
        "\n",
        "# print(f\"Job labeling completed. Labeled data saved to {output_json_path}\")\n",
        "\n",
        "# # Now 'resume_data' contains the contents of the JSON file\n",
        "# # print(json.dumps(resume_data, indent=2))\n",
        "\n",
        "# # # Load df1 from the Excel file\n",
        "# # df1_path = \"/content/DL world_cities_countries.csv\"\n",
        "# # df1 = pd.read_csv(df1_path)\n",
        "\n",
        "\n",
        "# # # def split_and_create_columns(location):\n",
        "# # #     if pd.notna(location):\n",
        "# # #         location = location.replace(',', ', ')\n",
        "# # #         substrings = re.split(r'[^\\w]+', location)\n",
        "# # #         substrings = [entry.strip() for entry in substrings]\n",
        "# # #         substrings = [remove_special_terms(entry) for entry in substrings]\n",
        "\n",
        "# # #         if any(\"justice\" in entry.lower() or \"precinct\" in entry.lower() for entry in substrings):\n",
        "# # #             substrings.append(\"new zealand\")\n",
        "\n",
        "# # #         if any(\"christchurch\" in entry.lower() or \"convention\" in entry.lower() for entry in substrings):\n",
        "# # #             substrings.append(\"new zealand\")\n",
        "\n",
        "# # #         return substrings\n",
        "\n",
        "# # #     return pd.NA\n",
        "\n",
        "# # # def remove_special_terms(substring):\n",
        "# # #     special_terms = [\"plaza\", \"street\", \"st\", \"road\", \"rd\", \"avenue\", \"close\", \"motorway\", \"highway\",\n",
        "# # #                      \"po\", \"PO\", \"new zealand|po\", \"office\", \"drive\", \"cor.\", \"ave.\", \"ave\", \"level\", \"lvl\",\n",
        "# # #                      \"box\", \"lv\", \"village\", \"vellage\", \"building\", \"bldg\", \"city\", \"albany\"]\n",
        "\n",
        "# # #     pattern = r'\\b(?:' + '|'.join(re.escape(term) for term in special_terms) + r')\\b'\n",
        "\n",
        "# # #     substring = re.sub(pattern, '', substring, flags=re.IGNORECASE).strip()\n",
        "\n",
        "# # #     if \"rubber\" in substring.lower():\n",
        "# # #         substring = substring.replace(\"rubber\", \"\").strip()\n",
        "\n",
        "# # #     if \"tire\" in substring.lower():\n",
        "# # #         substring = substring.replace(\"tire\", \"\").strip()\n",
        "\n",
        "# # #     return substring\n",
        "\n",
        "# # # if __name__ == \"__main__\":\n",
        "# # #     json_file_path2 = \"DL jobslabeled.json\"\n",
        "# # #     df = pd.json_normalize(json.load(open(json_file_path2, 'r'))['profile']['professional_experiences'])\n",
        "\n",
        "# # #     # Focus on the 'location' column\n",
        "# # #     df['location'] = df['location'].str.lower()\n",
        "# # #     new_columns = df['location'].apply(split_and_create_columns).apply(pd.Series)\n",
        "\n",
        "# # #     # Label the new columns with subscripts and append numbers\n",
        "# # #     new_columns.columns = [f'subscript_{i+1}' for i in range(new_columns.shape[1])]\n",
        "\n",
        "# # #     # Concatenate the new columns to the original DataFrame\n",
        "# # #     df = pd.concat([df, new_columns], axis=1)\n",
        "\n",
        "# # # Save df to a CSV file\n",
        "# # df.to_csv('DL output_data.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo9LKjwrrci1",
        "outputId": "875395b4-067e-4bb0-f8a6-8fd001e8d760"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job labeling completed. Labeled data saved to /content/DL jobslabeled.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CndfYExK5Wom",
        "outputId": "d12419b3-03cd-4393-b616-65aedce0fd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'mississippi' in the city/country DataFrame with 'United States' as the country?\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-02a78c02542b>:47: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['location'] = df['location'].str.replace(r'\\bmoss\\b', '', case=False)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Trying to get the coce to pick up UNited states as the country for Mississippi\n",
        "\n",
        "# this i was the latest code i put in, which didn't work....\n",
        "# # Create a new column 'Final_match'\n",
        "# df['Final_match'] = df.apply(lambda row:\n",
        "#                              row['countries_matched'] if pd.notna(row['countries_matched'])\n",
        "#                              else (df2[df2['city'].str.lower() == row['cities_matched'].lower()]['country'].values[-1]\n",
        "#                                    if not pd.isna(row['cities_matched']) else ''),\n",
        "#                              axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "# Load df & df1 & df2\n",
        "df_path = \"/content/DL output_data.csv\"\n",
        "df = pd.read_csv(df_path)\n",
        "\n",
        "df1_path = \"/content/DL world_countries.csv\"\n",
        "df1 = pd.read_csv(df1_path)\n",
        "\n",
        "df2_path = \"/content/DL world_cities_countries.csv\"\n",
        "df2 = pd.read_csv(df2_path)\n",
        "\n",
        "# Convert columns to string type\n",
        "df['location'] = df['location'].astype(str)\n",
        "df1['country'] = df1['country'].astype(str)\n",
        "df2['city'] = df2['city'].astype(str)\n",
        "\n",
        "# Create a new column 'countries_matched' in df\n",
        "df['countries_matched'] = df['location'].apply(lambda x: ', '.join(country for country in df1['country'] if f\" {country.lower()} \" in f\" {x.lower()} \"))\n",
        "\n",
        "# Create a new column 'cities_matched' in df\n",
        "df['cities_matched'] = df['location'].apply(lambda x: ', '.join(city for city in df2['city'] if f\" {city.lower()} \" in f\" {x.lower()} \"))\n",
        "\n",
        "# Amendments to search criteria\n",
        "condition = df['location'].str.contains('justice', case=False) & df['location'].str.contains('precinct', case=False)\n",
        "df.loc[condition, 'countries_matched'] = 'new zealand'\n",
        "# Remove 'moss' from the 'location' column\n",
        "df['location'] = df['location'].str.replace(r'\\bmoss\\b', '', case=False)\n",
        "\n",
        "\n",
        "# Create a new column 'Final_match' and capitalize all words\n",
        "df['Final_match'] = df.apply(lambda row:\n",
        "                             row['countries_matched'].title() if pd.notna(row['countries_matched'])\n",
        "                             else ('United States' if 'mississippi' in row['cities_matched'].lower() else ''),\n",
        "                             axis=1)\n",
        "\n",
        "\n",
        "# Helper function to get the final match value\n",
        "def get_final_match(row):\n",
        "    if row['countries_matched']:\n",
        "        # If countries_matched is not empty, take the last value\n",
        "        return row['countries_matched'].split(', ')[-1]\n",
        "    elif row['cities_matched']:\n",
        "        # If cities_matched is not empty, look up the country in df2\n",
        "        city_countries = df2[df2['city'].str.contains(row['cities_matched'], case=False)]\n",
        "        if not city_countries.empty:\n",
        "            return city_countries['country'].values[-1]\n",
        "    return \"\"\n",
        "\n",
        "# Apply the helper function to fill 'Final_match'\n",
        "df['Final_match'] = df.apply(get_final_match, axis=1)\n",
        "\n",
        "\n",
        "# Capitalize all words in 'Final_match' column\n",
        "df['Final_match'] = df['Final_match'].apply(lambda x: ' '.join(word.capitalize() for word in x.split()))\n",
        "\n",
        "\n",
        "\n",
        "# Save df to a CSV file with the desired name\n",
        "df.to_csv('DL output_data.csv', index=False)\n",
        "\n",
        "# Check if 'mississippi' is in the city/country DataFrame with 'United States' as the country\n",
        "mississippi_check = df2[df2['city'].str.contains('mississippi', case=False) & (df2['country'].str.lower() == 'united states')]\n",
        "\n",
        "# Print the result\n",
        "print(\"Is 'mississippi' in the city/country DataFrame with 'United States' as the country?\")\n",
        "print(not mississippi_check.empty)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Printing for troubleshooting\n",
        "# for index, row in df.iterrows():\n",
        "#     print(f\"Row {index + 1}:\")\n",
        "#     print(f\"  Countries Matched: {row.get('countries_matched', '')}\")\n",
        "#     print(f\"  Cities Matched: {row.get('cities_matched', '')}\")\n",
        "#     print(f\"  Final Match: {row.get('Final_match', '')}\")\n",
        "#     print()\n",
        "\n",
        "# # Filter rows where 'city' is equal to 'ica'\n",
        "# filtered_rows = df2[df2['city'].apply(lambda x: f\" ica \" in f\" {x.lower()} \")]\n",
        "\n",
        "# # Print the result\n",
        "# print(filtered_rows)\n",
        "\n",
        "# Display the DataFrame or perform any other operations as needed\n",
        "# print(df.head())\n",
        "\n",
        "# # Look up countries with the city 'k.s.a'\n",
        "# countries_with_ksa = df2[df2['city'].str.contains('k.s.a')]['country'].unique()\n",
        "\n",
        "\n",
        "\n",
        "# # Assuming df1 is your dataframe containing cities\n",
        "# print(df2['city'].unique())\n",
        "\n",
        "\n",
        "\n",
        "# # Print the result\n",
        "# # print(\"Countries with the city 'K.S.A':\", countries_with_ksa)\n"
      ]
    }
  ]
}