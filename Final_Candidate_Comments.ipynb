{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjFymV7vXRKjtWobG3+bGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nzcbass/Pythontoopenai/blob/main/Final_Candidate_Comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rObckIqjhQFK",
        "outputId": "861a9a39-7a09-44e2-8a51-6d38d3dba3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-bb3d7b6d4450>:52: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  df4 = df4.groupby('Candidate Name', as_index=False).apply(update_job_owner_and_client)\n",
            "<ipython-input-64-bb3d7b6d4450>:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df5['First Name'] = df5['First Name'].str.strip()\n",
            "<ipython-input-64-bb3d7b6d4450>:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df5['Surname'] = df5['Surname'].str.strip()\n",
            "<ipython-input-64-bb3d7b6d4450>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df5['Full Name'] = df5['First Name'] + ' ' + df5['Surname']\n",
            "<ipython-input-64-bb3d7b6d4450>:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('1st Day Call', '1. 1st Day Call')\n",
            "<ipython-input-64-bb3d7b6d4450>:96: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 1st week', '2. F/up - End of the 1st week')\n",
            "<ipython-input-64-bb3d7b6d4450>:97: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 2nd week', '3. F/up - End of the 2nd week')\n",
            "<ipython-input-64-bb3d7b6d4450>:104: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('18. Month 13 F/up Due Date Calculated', '18. Month 13 F/up')\n",
            "<ipython-input-64-bb3d7b6d4450>:105: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('19. Month 14 F/up Due Date Calculated', '19. Month 14 F/up')\n",
            "<ipython-input-64-bb3d7b6d4450>:106: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('20. Month 15 F/up Due Date Calculated', '20. Month 15 F/up')\n",
            "<ipython-input-64-bb3d7b6d4450>:107: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('21. Month 16 F/up Due Date Calculated', '21. Month 16 F/up')\n",
            "<ipython-input-64-bb3d7b6d4450>:108: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('22. Month 17 F/up Due Date Calculated', '22. Month 17 F/up')\n",
            "<ipython-input-64-bb3d7b6d4450>:109: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df1['Standard Description'] = df1['Standard Description'].str.replace('23. Month 18 F/up Due Date Calculated', '23. Month 18 F/up')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Job Owner                      Client Name          Position  \\\n",
            "0     Samaria October                     Test Company         Carpenter   \n",
            "1     Clayton Badland              CB Civil & Drainage   Civil Carpenter   \n",
            "2       Thomas Denyer  Fitzgerald Construction Limited         Carpenter   \n",
            "3    Eugene Lamprecht             VAE NZ Ltd - Waikato       Duct Fitter   \n",
            "4    Brittany Skelton                   Rokane Limited         Carpenter   \n",
            "..                ...                              ...               ...   \n",
            "252    Morsal Darwesh    Caldwell and Levesque Limited       Electrician   \n",
            "253  Eugene Lamprecht                 Aotea Electrical       Electrician   \n",
            "254     Thomas Denyer  Fitzgerald Construction Limited         Carpenter   \n",
            "255      Elliot Dixon       Isaac Construction Dunedin  Machine Operator   \n",
            "256     Raeleen Evans        VAE NZ Ltd - Christchurch       Duct Fitter   \n",
            "\n",
            "     Status Report to Contact Start Date    End Date      Candidate Name  \\\n",
            "0    Closed               NaN 2022-10-31  26/03/2023          Aaron Test   \n",
            "1    Filled      David Hopper 2023-09-06   2/06/2024     Adrian Gragasin   \n",
            "2    Filled     Charlie Evans 2023-01-23  17/01/2024     Adrian Sasutona   \n",
            "3    Filled      Sam Crawford 2023-11-13  29/02/2024  Alberto Jr. Santos   \n",
            "4    Filled     Belen Ramirez 2023-01-09  10/02/2024         Aldwin Daiz   \n",
            "..      ...               ...        ...         ...                 ...   \n",
            "252  Closed      Ben Levesque 2023-10-12  10/12/2023     Victor Oliveira   \n",
            "253  Closed       Mihaela Cuc 2023-02-20   9/04/2023     Vishal Dungrani   \n",
            "254  Filled     Charlie Evans 2023-01-23  31/03/2024       Von Ryan Otic   \n",
            "255  Filled    Tinelle Rolton 2023-04-17  31/03/2024  Welfredo Mantillas   \n",
            "256  Closed   Makaela Dowling 2023-07-27   3/09/2023               Yi Hu   \n",
            "\n",
            "     Candidate ID    Job No.  ... 14. Month 9 F/up  15. Month 10 F/up  \\\n",
            "0       100005832  200002432  ...                                       \n",
            "1       100012902  200002863  ...                                       \n",
            "2       100010663  200002510  ...              Yes                Yes   \n",
            "3       100013548  200002975  ...                                       \n",
            "4       100000204  200002489  ...                                       \n",
            "..            ...        ...  ...              ...                ...   \n",
            "252     100013127  200002912  ...                                       \n",
            "253     100007991  200002542  ...                                       \n",
            "254     100010659  200002509  ...              Yes                Yes   \n",
            "255     100011337  200002652  ...                                 Yes   \n",
            "256     100012623  200002818  ...                                       \n",
            "\n",
            "    16. Month 11 F/up 17. Month 12 F/up  18. Month 13 F/up  19. Month 14 F/up  \\\n",
            "0                                                                               \n",
            "1                                                                               \n",
            "2                                                                               \n",
            "3                                                                               \n",
            "4                                                                               \n",
            "..                ...               ...                ...                ...   \n",
            "252                                                                             \n",
            "253                                                                             \n",
            "254                                                                             \n",
            "255                                                                             \n",
            "256                                                                             \n",
            "\n",
            "    20. Month 15 F/up 21. Month 16 F/up 22. Month 17 F/up 23. Month 18 F/up  \n",
            "0                                                                            \n",
            "1                                                                            \n",
            "2                                                                            \n",
            "3                                                                            \n",
            "4                                                                            \n",
            "..                ...               ...               ...               ...  \n",
            "252                                                                          \n",
            "253                                                                          \n",
            "254                                                                          \n",
            "255                                                                          \n",
            "256                                                                          \n",
            "\n",
            "[257 rows x 45 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-bb3d7b6d4450>:196: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
            "  if due_date > today and (next_due_date is None or due_date < next_due_date):\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# DF1 Run Candidate comments from FT 1/9/22 onwards and save down as CandidateComments.csv\n",
        "# df3 upload Perioddatesweeks\n",
        "# run filled and closed jobs report save as JobOrders.csv from 1/9/22 onwards\n",
        "# Run AEWV report from FT and save as AEWVList.csv\n",
        "\n",
        "\n",
        "# THis code works up to generating next action and next action date\n",
        "# The next script provides missing activity with dates and future comments from FT\n",
        "\n",
        "\n",
        "file_path1 = '/content/CandidateComments.csv'\n",
        "file_path3 = '/content/Perioddatesweeks.csv'\n",
        "file_path4 = '/content/JobOrders.csv'\n",
        "file_path5 = '/content/AEWVList.csv'\n",
        "\n",
        "columns_to_include = ['Entity Name', 'Client Name', 'Contact Name', 'Candidate Name', 'Comment Type', 'Standard Description', 'Comment Date', 'Comment']\n",
        "\n",
        "df1 = pd.read_csv(file_path1, usecols=columns_to_include)\n",
        "# df2 = pd.read_csv(file_path2)\n",
        "df3 = pd.read_csv(file_path3)\n",
        "df4 = pd.read_csv(file_path4)\n",
        "df5 = pd.read_csv(file_path5)\n",
        "\n",
        "# Remove all rows where 'Client Name' is 'Turbo Staff'\n",
        "df4 = df4[df4['Client Name'] != 'Turbo Staff Ltd']\n",
        "\n",
        "# Remove the 'Office' column from df4\n",
        "df4 = df4.drop('Office', axis=1)\n",
        "\n",
        "# Drop rows where 'Position Type' column includes the word 'Permanent'\n",
        "df4 = df4[~df4['Position Type'].str.contains('Permanent', na=False)]\n",
        "\n",
        "# Convert 'Start Date' to datetime with the correct format\n",
        "df4['Start Date'] = pd.to_datetime(df4['Start Date'], format='%d/%m/%Y')\n",
        "\n",
        "# Sort the DataFrame by 'Candidate Name' and 'Start Date'\n",
        "df4 = df4.sort_values(by=['Candidate Name', 'Start Date'])\n",
        "\n",
        "# Define a function that takes a subset DataFrame and replaces the 'Job Owner' and 'Client Name' values\n",
        "def update_job_owner_and_client(group):\n",
        "    if len(group) > 1:  # More than one entry for the candidate\n",
        "        # Set the 'Job Owner' of the first job to be the 'Job Owner' of the last job\n",
        "        group['Job Owner'].iloc[0] = group['Job Owner'].iloc[-1]\n",
        "        # Set the 'Client Name' of the first job to be the 'Client Name' of the last job\n",
        "        group['Client Name'].iloc[0] = group['Client Name'].iloc[-1]\n",
        "    return group\n",
        "\n",
        "# Apply the function to each group of 'Candidate Name'\n",
        "df4 = df4.groupby('Candidate Name', as_index=False).apply(update_job_owner_and_client)\n",
        "\n",
        "# Depending on the pandas version, the indexing might be altered, so reset it\n",
        "df4.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Drop duplicates, keeping the first (earliest date) for each candidate\n",
        "df4 = df4.drop_duplicates(subset='Candidate Name', keep='first')\n",
        "\n",
        "df4.to_csv('df4.csv', index=False)\n",
        "\n",
        "# Remove rows where 'Status' column contains the word 'inactive'\n",
        "df5 = df5[df5['Status'].str.lower() != 'inactive']\n",
        "\n",
        "# Remove leading whitespaces from 'First Name' and 'Surname'\n",
        "df5['First Name'] = df5['First Name'].str.strip()\n",
        "df5['Surname'] = df5['Surname'].str.strip()\n",
        "\n",
        "# Create new columns 'Full Name' by merging 'First Name' and 'Surname' for DF5\n",
        "df5['Full Name'] = df5['First Name'] + ' ' + df5['Surname']\n",
        "\n",
        "# # Merge df4 and df5 to check for matching names\n",
        "# merged_df = df4.merge(df5, left_on='Candidate Name', right_on='Full Name', how='left')\n",
        "\n",
        "# # Create the 'AEWV' column based on the merge result\n",
        "# merged_df['AEWV'] = merged_df.apply(lambda row: 'Yes' if pd.notna(row['Full Name']) else 'No', axis=1)\n",
        "\n",
        "# # Update the 'AEWV' column in df4 with values from merged_df\n",
        "# df4['AEWV'] = merged_df['AEWV']\n",
        "\n",
        "# Create a set of full names from df5 for efficient lookup\n",
        "full_names_set = set(df5['Full Name'])\n",
        "\n",
        "# Function to check if a candidate name is in the full names set\n",
        "def check_name_in_df5(candidate_name):\n",
        "    return 'Yes' if candidate_name in full_names_set else 'No'\n",
        "\n",
        "# Apply the function to each row in df4 and create the new 'AEWV' column\n",
        "df4['AEWV'] = df4['Candidate Name'].apply(check_name_in_df5)\n",
        "\n",
        "# Remove rows where \"entity name\" is blank\n",
        "df1 = df1.dropna(subset=[\"Entity Name\"])\n",
        "\n",
        "# Rename columns to match output\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('1st Day Call', '1. 1st Day Call')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 1st week', '2. F/up - End of the 1st week')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 2nd week', '3. F/up - End of the 2nd week')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 3rd week', '4. F/up - End of the 3rd week')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 4th week', '5. F/up - End of the 4th week')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 6th week', '6. F/up - End of the 6th week')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('F/up - End of the 8th week', '7. F/up - End of the 8th week')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('Month 4 F/up', '9. Month 4 F/up')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('Month 5 F/up', '10. Month 5 F/up')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('18. Month 13 F/up Due Date Calculated', '18. Month 13 F/up')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('19. Month 14 F/up Due Date Calculated', '19. Month 14 F/up')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('20. Month 15 F/up Due Date Calculated', '20. Month 15 F/up')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('21. Month 16 F/up Due Date Calculated', '21. Month 16 F/up')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('22. Month 17 F/up Due Date Calculated', '22. Month 17 F/up')\n",
        "df1['Standard Description'] = df1['Standard Description'].str.replace('23. Month 18 F/up Due Date Calculated', '23. Month 18 F/up')\n",
        "\n",
        "merged_df = df4.merge(df1[df1[\"Comment Type\"] == \"Candidate\"], left_on=[\"Candidate Name\"], right_on=[\"Entity Name\"], how=\"left\")\n",
        "\n",
        "# Comments to check\n",
        "comments_to_check = [\"1. 1st Day Call\", \"2. F/up - End of the 1st week\", \"3. F/up - End of the 2nd week\",\n",
        "                     \"4. F/up - End of 3rd week\", \"5. F/up - End of the 4th week\", \"6. F/up - End of the 6th week\",\n",
        "                     \"7. F/up - End of the 8th week\", \"8. Month 3 F/up\", \"9. Month 4 F/up\", \"10. Month 5 F/up\",\n",
        "                     \"11. Month 6 F/up\", \"12. Month 7 F/up\", \"13. Month 8 F/up\", \"14. Month 9 F/up\",\n",
        "                     \"15. Month 10 F/up\", \"16. Month 11 F/up\", \"17. Month 12 F/up\", \"18. Month 13 F/up\",\n",
        "                     \"19. Month 14 F/up\", \"20. Month 15 F/up\", \"21. Month 16 F/up\", \"22. Month 17 F/up\", \"23. Month 18 F/up\"]\n",
        "\n",
        "# Create columns for each comment and populate with 'yes' if the comment exists\n",
        "for comment in comments_to_check:\n",
        "    merged_df[comment] = merged_df.apply(lambda row: 'Yes' if comment in str(row[\"Standard Description\"]) else '', axis=1)\n",
        "\n",
        "# Group by 'Candidate Name_x' and aggregate 'yes' values\n",
        "grouped_df = merged_df.groupby('Candidate Name_x', as_index=False).agg(\n",
        "    {comment: 'max' for comment in comments_to_check}\n",
        ")\n",
        "\n",
        "# Merge grouped_df with df4 to keep all columns\n",
        "consolidated_df = df4.merge(grouped_df, left_on='Candidate Name', right_on='Candidate Name_x', how='left')\n",
        "\n",
        "print(consolidated_df)\n",
        "\n",
        "# Define the due_date_rules dictionary\n",
        "due_date_rules = {\n",
        "    '1. 1st Day Call': timedelta(days=0),\n",
        "    '2. F/up - End of the 1st week': timedelta(days=7),\n",
        "    '3. F/up - End of the 2nd week': timedelta(days=14),\n",
        "    '4. F/up - End of 3rd week': timedelta(days=21),\n",
        "    '5. F/up - End of the 4th week': timedelta(days=28),\n",
        "    '6. F/up - End of the 6th week': timedelta(days=42),\n",
        "    '7. F/up - End of the 8th week': timedelta(days=56),\n",
        "    '8. Month 3 F/up': timedelta(days=84),\n",
        "    '9. Month 4 F/up': timedelta(days=112),\n",
        "    '10. Month 5 F/up': timedelta(days=140),\n",
        "    '11. Month 6 F/up': timedelta(days=168),\n",
        "    '12. Month 7 F/up': timedelta(days=196),\n",
        "    '13. Month 8 F/up': timedelta(days=224),\n",
        "    '14. Month 9 F/up': timedelta(days=252),\n",
        "    '15. Month 10 F/up': timedelta(days=280),\n",
        "    '16. Month 11 F/up': timedelta(days=308),\n",
        "    '17. Month 12 F/up': timedelta(days=336),\n",
        "    '18. Month 13 F/up': timedelta(days=364),\n",
        "    '19. Month 14 F/up': timedelta(days=392),\n",
        "    '20. Month 15 F/up': timedelta(days=420),\n",
        "    '21. Month 16 F/up': timedelta(days=448),\n",
        "    '22. Month 17 F/up': timedelta(days=476),\n",
        "    '23. Month 18 F/up': timedelta(days=494),\n",
        "    '24. Month 19 F/up': timedelta(days=522),\n",
        "    '25. Month 20 F/up': timedelta(days=546),\n",
        "    '26. Month 21 F/up': timedelta(days=574),\n",
        "    '27. Month 22 F/up': timedelta(days=602),\n",
        "    '28. Month 23 F/up': timedelta(days=630),\n",
        "    '29. Month 24 F/up': timedelta(days=658),\n",
        "    '30. Month 25 F/up': timedelta(days=686)\n",
        "    # ... Add more columns and due date rules as needed\n",
        "}\n",
        "\n",
        "# print(consolidated_df)\n",
        "\n",
        "# # Save the modified DataFrame to a CSV file\n",
        "consolidated_df.to_csv('candicommentsjobsmerged.csv', index=False)\n",
        "\n",
        "# Convert 'Start Date' column to datetime type\n",
        "consolidated_df['Start Date'] = pd.to_datetime(consolidated_df['Start Date'], format='%d/%m/%Y')\n",
        "\n",
        "# Iterate over columns and calculate due dates\n",
        "for column, rule in due_date_rules.items():\n",
        "    consolidated_df[column + ' Due Date'] = consolidated_df['Start Date'].apply(lambda start_date: start_date + rule)\n",
        "\n",
        "# Calculate today's date\n",
        "today = datetime.today().date()\n",
        "\n",
        "# Create new columns to store next action and next due date\n",
        "consolidated_df['Next Action'] = \"\"\n",
        "consolidated_df['Next Due Date'] = None\n",
        "\n",
        "# Iterate over rows and find next action and due date\n",
        "for index, row in consolidated_df.iterrows():\n",
        "    next_action = None\n",
        "    next_due_date = None\n",
        "\n",
        "    for column, rule in due_date_rules.items():\n",
        "        due_date = row['Start Date'] + rule\n",
        "        if due_date > today and (next_due_date is None or due_date < next_due_date):\n",
        "            next_due_date = due_date\n",
        "            next_action = column\n",
        "\n",
        "    consolidated_df.at[index, 'Next Action'] = next_action\n",
        "    consolidated_df.at[index, 'Next Due Date'] = next_due_date\n",
        "\n",
        "# Convert 'Next Due Date' column to datetime type\n",
        "consolidated_df['Next Due Date'] = pd.to_datetime(consolidated_df['Next Due Date'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing or invalid 'Next Due Date' values\n",
        "consolidated_df = consolidated_df[consolidated_df['Next Due Date'].notna()]\n",
        "\n",
        "\n",
        "# Change the date format in the \"Next Due Date\" column to \"yyyy/mm/dd\"\n",
        "consolidated_df['Next Due Date'] = pd.to_datetime(consolidated_df['Next Due Date'], format='%d/%m/%y').dt.strftime('%Y/%m/%d')\n",
        "\n",
        "# Print the modified DataFrame\n",
        "# print(consolidated_df)\n",
        "\n",
        "# Save the modified DataFrame to a CSV file\n",
        "consolidated_df.to_csv('candicommentsjobsmerged.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Load your DataFrame\n",
        "file_path1 = '/content/candicommentsjobsmerged.csv'\n",
        "df1 = pd.read_csv(file_path1)\n",
        "\n",
        "# List of activity columns in numerical order\n",
        "activity_columns = [\n",
        "    '1. 1st Day Call', '2. F/up - End of the 1st week', '3. F/up - End of the 2nd week',\n",
        "    '4. F/up - End of 3rd week', '5. F/up - End of the 4th week', '6. F/up - End of the 6th week',\n",
        "    '7. F/up - End of the 8th week', '8. Month 3 F/up', '9. Month 4 F/up', '10. Month 5 F/up',\n",
        "    '11. Month 6 F/up', '12. Month 7 F/up', '13. Month 8 F/up', '14. Month 9 F/up',\n",
        "    '15. Month 10 F/up', '16. Month 11 F/up', '17. Month 12 F/up', '18. Month 13 F/up',\n",
        "    '19. Month 14 F/up', '20. Month 15 F/up', '21. Month 16 F/up', '22. Month 17 F/up',\n",
        "    '23. Month 18 F/up', '24. Month 19 F/up', '25. Month 20 F/up', '26. Month 21 F/up',\n",
        "    '27. Month 22 F/up', '28. Month 23 F/up', '29. Month 24 F/up', '30. Month 25 F/up' # Add any additional columns here\n",
        "]\n",
        "\n",
        "# Find the index of '17. Month 12 F/up'\n",
        "# insert_index = df1.columns.get_loc('17. Month 12 F/up')\n",
        "\n",
        "# Add missing columns in reversed numerical order after '17. Month 12 F/up'\n",
        "missing_columns = sorted(set(activity_columns) - set(df1.columns), key=lambda x: int(x.split('.')[0]), reverse=True)\n",
        "for col in missing_columns:\n",
        "    df1.insert(insert_index + 1, col, '')\n",
        "\n",
        "# Define a dictionary to map activity columns to due date columns\n",
        "activity_to_due_date = {activity_col: f'{activity_col} Due Date' for activity_col in activity_columns}\n",
        "\n",
        "# Remove rows where 'AEWV' column is 'No'\n",
        "df1 = df1[df1['AEWV'] != 'No']\n",
        "\n",
        "# Remove rows where 'AEWV' column is blank\n",
        "df1 = df1[df1['AEWV'].notna()]\n",
        "\n",
        "# Loop through each row\n",
        "for index, row in df1.iterrows():\n",
        "    for activity_col, due_date_col in activity_to_due_date.items():\n",
        "        if activity_col not in row:\n",
        "            continue  # Skip columns not present in the DataFrame\n",
        "\n",
        "        if row[activity_col] == 'Yes':\n",
        "            continue  # If it's 'Yes', move to the next column\n",
        "\n",
        "        due_date = row.get(due_date_col)  # Use .get() to handle missing columns\n",
        "        if pd.isna(due_date):\n",
        "            continue  # If due date is also missing, move to the next column\n",
        "\n",
        "        # Convert due date to datetime object\n",
        "        due_date = pd.to_datetime(due_date)\n",
        "\n",
        "        # Check if the due date is in the past or today\n",
        "        if due_date <= datetime.today():\n",
        "            df1.at[index, activity_col] = due_date.strftime('%Y-%m-%d')  # Populate the cell\n",
        "\n",
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'Status', 'Report to Contact', 'End Date', 'Candidate Name', 'Candidate ID',\n",
        "    'Job No.', 'Position Type', 'Type', 'Filled Date', 'Parent Name', 'Client No.', 'Cost Centre ID',\n",
        "    'Cost Centre Name', ' Order by Contact', 'Site Contact', 'Order Date & Time',\n",
        "    '1. 1st Day Call Due Date', '2. F/up - End of the 1st week Due Date',\n",
        "    '3. F/up - End of the 2nd week Due Date', '4. F/up - End of 3rd week Due Date',\n",
        "    '5. F/up - End of the 4th week Due Date', '6. F/up - End of the 6th week Due Date',\n",
        "    '7. F/up - End of the 8th week Due Date', '8. Month 3 F/up Due Date', '9. Month 4 F/up Due Date',\n",
        "    '10. Month 5 F/up Due Date', '11. Month 6 F/up Due Date', '12. Month 7 F/up Due Date',\n",
        "    '13. Month 8 F/up Due Date', '14. Month 9 F/up Due Date', '15. Month 10 F/up Due Date',\n",
        "    '16. Month 11 F/up Due Date', '17. Month 12 F/up Due Date', '18. Month 13 F/up Due Date',\n",
        "    '19. Month 14 F/up Due Date', '20. Month 15 F/up Due Date', '21. Month 16 F/up Due Date',\n",
        "    '22. Month 17 F/up Due Date', '23. Month 18 F/up Due Date', '24. Month 19 F/up Due Date',\n",
        "    '25. Month 20 F/up Due Date', '26. Month 21 F/up Due Date', '27. Month 22 F/up Due Date',\n",
        "    '28. Month 23 F/up Due Date', '29. Month 24 F/up Due Date', '30. Month 25 F/up Due Date'\n",
        "]\n",
        "\n",
        "# Define a function to extract numbers from a column name\n",
        "def extract_number(col_name):\n",
        "    # Split the column name by spaces and take the first part which should contain the number\n",
        "    num_part = col_name.split()[0]\n",
        "    # Extract digits from the part\n",
        "    digits = ''.join(filter(str.isdigit, num_part))\n",
        "    # Convert to integer if not empty, otherwise return a large number so it sorts last\n",
        "    return int(digits) if digits else float('inf')\n",
        "\n",
        "# Create a mapping of column names to the extracted numbers\n",
        "column_mapping = {col: extract_number(col) for col in df1.columns}\n",
        "\n",
        "# Sort the columns by the extracted numbers\n",
        "sorted_columns = sorted(df1.columns, key=lambda col: column_mapping[col])\n",
        "\n",
        "# Reindex the DataFrame with the sorted column names\n",
        "df1 = df1[sorted_columns]\n",
        "\n",
        "# Rename 'Start Date' column to 'Date First Employed'\n",
        "df1 = df1.rename(columns={'Start Date': 'Date First Employed'})\n",
        "\n",
        "# Sort df1 by 'Job Owner' first, then by 'Candidate Name_x'\n",
        "df1 = df1.sort_values(by=['Job Owner', 'Candidate Name_x'])\n",
        "\n",
        "# Remove specified columns\n",
        "df1 = df1.drop(columns=columns_to_remove)\n",
        "\n",
        "df1['Next Due Date'] = pd.to_datetime(df1['Next Due Date'])\n",
        "\n",
        "# List of columns that should come first, in the order you specified\n",
        "specified_columns = ['Job Owner', 'Client Name', 'Position', 'Date First Employed', 'AEWV', 'Candidate Name_x', 'Next Action', 'Next Due Date']\n",
        "\n",
        "# List of all columns that start with a number using a list comprehension\n",
        "numeric_columns = [col for col in df1.columns if col[0].isdigit()]\n",
        "\n",
        "# Concatenate the lists, ensuring that the specified columns come first\n",
        "new_column_order = specified_columns + numeric_columns\n",
        "\n",
        "# Reindex the DataFrame with the new column order\n",
        "df1 = df1[new_column_order]\n",
        "\n",
        "# Save the modified DataFrame to a new file\n",
        "modified_file_path = '/content/MissingAEWVActivitiesDate.csv'\n",
        "df1.to_csv(modified_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "ZeKZBXaJQtCR"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}